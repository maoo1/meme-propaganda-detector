{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["link to our [sem eval task](https://propaganda.math.unipd.it/semeval2024task4/teampage.php?passcode=7a4c50dc60f44593a07529d2253593e9)\n","\n","to do:\n","- import models\n","- finetune models\n","- evaluate models\n","- adjust test data to be list of applicable labels instead of / separated"],"metadata":{"id":"yGGoy1eh7d6E"}},{"cell_type":"markdown","source":["\n","# Setting up libraries and mounting google drive\n","\n","\n"],"metadata":{"id":"ARK95eVKc77d"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuVfr1Ia-Rwz","executionInfo":{"status":"ok","timestamp":1733525562228,"user_tz":300,"elapsed":13191,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}},"outputId":"bf5becc5-c704-4750-da11-eb4bb1aef7c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Collecting gdown==v4.6.3\n","  Downloading gdown-4.6.3-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==v4.6.3) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==v4.6.3) (2.32.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==v4.6.3) (1.16.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==v4.6.3) (4.12.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec (from torch)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==v4.6.3) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==v4.6.3) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==v4.6.3) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==v4.6.3) (2024.8.30)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==v4.6.3) (2.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==v4.6.3) (1.7.1)\n","Downloading gdown-4.6.3-py3-none-any.whl (14 kB)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, gdown, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 5.2.0\n","    Uninstalling gdown-5.2.0:\n","      Successfully uninstalled gdown-5.2.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 gdown-4.6.3 multiprocess-0.70.16 xxhash-3.5.0\n"]}],"source":["# install dependencies and codebase\n","# transformers Hugging Face library: access to BERT / GPT\n","!pip install torch transformers datasets tqdm gdown==v4.6.3\n","!mkdir checkpoints"]},{"cell_type":"markdown","source":[],"metadata":{"id":"n5qoqEgkALxK"}},{"cell_type":"code","source":["# mounting data and files to drive\n","# hypothetically can upload SemEval datasets to drive for easier access + we would both have access\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZGjFcsyBNOt","executionInfo":{"status":"ok","timestamp":1733525585653,"user_tz":300,"elapsed":23432,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}},"outputId":"e2eab912-7ab7-4003-f26f-8af4ffb94f7c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Preprocessing the Data"],"metadata":{"id":"grW6aACJiSt_"}},{"cell_type":"code","source":["import json\n","from dataclasses import dataclass\n","from typing import List, Dict, Tuple, Union\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer"],"metadata":{"id":"rif5mVhOiW9M","executionInfo":{"status":"ok","timestamp":1733525701539,"user_tz":300,"elapsed":122,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["creating Meme object and dataset"],"metadata":{"id":"DAAcbDU_CP9J"}},{"cell_type":"code","source":["# represents single meme as text, label\n","@dataclass\n","class Meme:\n","  text: str\n","  labels: Union[List[str], None] # labels can be none for test data\n","\n","  @staticmethod\n","  def from_dict(data: dict):\n","    text = data[\"text\"]\n","    labels = data.get(\"labels\", None)\n","    return Meme(text=text, labels=labels)\n","\n","# custom dataset for meme data, supporting multi-label classification\n","class MemeDataset(Dataset):\n","\n","  def __init__(self, tokenizer, data: List[Dict], label_encoder=None):\n","    MemeDataset.tokenizer = tokenizer\n","    self.examples = [Meme.from_dict(item) for item in data]\n","    self.label_encoder = label_encoder\n","\n","    if label_encoder:\n","      # encode labels if available\n","      self.encoded_labels = [label_encoder.transform([item.labels])[0] if item.labels else None\n","                                   for item in self.examples]\n","    else:\n","      self.encoded_labels = None\n","\n","  def __len__(self):\n","    return len(self.examples)\n","\n","  def __getitem__(self, idx):\n","    return self.examples[idx]\n","\n","  # batch processing\n","  @staticmethod\n","  def collate_fn(batched_samples: List[Meme], max_length=512):\n","\n","    batched_texts = [sample.text for sample in batched_samples]\n","    batched_labels = [sample.labels for sample in batched_samples if sample.labels is not None]\n","\n","    text_encoding = MemeDataset.tokenizer(\n","        batched_texts,\n","        padding=True,\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors=\"pt\"\n","    )\n","\n","    if batched_labels:\n","      labels_tensor = torch.tensor(batched_labels, dtype=torch.float32) # multi-label as float\n","    else:\n","      labels_tensor = None\n","\n","    return {\n","        \"input_ids\": text_encoding[\"input_ids\"],\n","        \"attention_mask\": text_encoding[\"attention_mask\"],\n","        \"labels\": labels_tensor,\n","    }\n"],"metadata":{"id":"lWnMg3fp3vlX","executionInfo":{"status":"ok","timestamp":1733528164579,"user_tz":300,"elapsed":115,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()"],"metadata":{"id":"1aC7GpnMCA8-","executionInfo":{"status":"ok","timestamp":1733525730462,"user_tz":300,"elapsed":3734,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def load_json(file_path):\n","  with open(file_path, 'r') as f:\n","    return json.load(f)\n","\n","# accessing the datasets from drive\n","train_file_path = '/content/drive/MyDrive/NLP_FINAL/train.json'\n","val_file_path = '/content/drive/MyDrive/NLP_FINAL/validation.json'\n","dev_unlabeled_file_path = '/content/drive/MyDrive/NLP_FINAL/dev_unlabeled.json'\n","test_file_path = '/content/drive/MyDrive/NLP_FINAL/dev_subtask1_en.json'\n","\n","raw_datasets = {}\n","\n","raw_datasets[\"train\"] = load_json(train_file_path)\n","raw_datasets[\"validation\"] = load_json(val_file_path)\n","raw_datasets[\"dev\"] = load_json(dev_unlabeled_file_path)\n","raw_datasets['test'] = load_json(test_file_path)\n","\n","print(raw_datasets[\"train\"][0])\n","print(type(raw_datasets['train'][0]))\n","print(raw_datasets['train'][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMZXudsGjYgj","executionInfo":{"status":"ok","timestamp":1733528236291,"user_tz":300,"elapsed":557,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}},"outputId":"08a1170e-b90b-4f78-97d1-2244f84955bb"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': '65635', 'text': 'THIS IS WHY YOU NEED\\\\n\\\\nA SHARPIE WITH YOU AT ALL TIMES', 'labels': ['Black-and-white Fallacy/Dictatorship'], 'link': 'https://www.facebook.com/photo/?fbid=4023552137722493&set=g.633131750534436'}\n","<class 'dict'>\n","THIS IS WHY YOU NEED\\n\\nA SHARPIE WITH YOU AT ALL TIMES\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","\n","datasets = {}\n","for split_name in raw_datasets.keys():\n","  split_data = list(raw_datasets[split_name])\n","\n","  datasets[split_name] = MemeDataset(tokenizer, split_data)\n","\n","validation_dataloader = DataLoader(datasets['validation'],\n","                                   batch_size=64,\n","                                   shuffle=False,\n","                                   collate_fn=MemeDataset.collate_fn,\n","                                   num_workers=2)\n","\n","print(datasets[\"train\"][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XW-Sqh2TIx98","executionInfo":{"status":"ok","timestamp":1733528238864,"user_tz":300,"elapsed":1156,"user":{"displayName":"Isabel Snyder","userId":"16227727973435882599"}},"outputId":"d8e072fa-38ff-4c2c-dcf1-d20d265f48cb"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Meme(text='THIS IS WHY YOU NEED\\\\n\\\\nA SHARPIE WITH YOU AT ALL TIMES', labels=['Black-and-white Fallacy/Dictatorship'])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"phHCoT49WG7f"},"execution_count":null,"outputs":[]}]}